{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"701e044f2f9145bb8b8dee099d880509","deepnote_cell_type":"markdown"},"source":"# ğŸ¤ trustcallï¼šæ›´å¯é çš„ç»“æ„åŒ–è¾“å‡º\n\nLLM åœ¨è¢«è¦æ±‚ç”Ÿæˆæˆ–ä¿®æ”¹å¤§å‹ JSON å—æ—¶ä¼šæœ‰æ‰€æŒ£æ‰ã€‚ [trustcall](https://github.com/hinthornw/trustcall) é€šè¿‡è¦æ±‚ LLM ç”Ÿæˆ [JSON Patch](https://www.genspark.ai/spark/understanding-json-patch/d07b30ec-813e-47da-8d1c-9a36923501f1) æ“ä½œæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¿™ä½¿èƒ½å¤Ÿï¼š\n\n- âš¡ æ›´å¿«æ›´ä¾¿å®œçš„ç”Ÿæˆç»“æ„åŒ–è¾“å‡º\n- ğŸ¶ å¯¹éªŒè¯é”™è¯¯çš„å¼¹æ€§é‡è¯•ï¼Œå³ä½¿æ˜¯å¤æ‚ã€åµŒå¥—çš„ç»“æ„ï¼ˆå®šä¹‰ä¸º pydanticã€ç»“æ„å­—å…¸æˆ–å¸¸è§„ Python å‡½æ•°ï¼‰\n- ğŸ§© å¯¹ç°æœ‰ç»“æ„çš„å‡†ç¡®æ›´æ–°ï¼Œé¿å…ä¸å¸Œæœ›çš„åˆ é™¤\n\ntrustcall çš„æ ¸å¿ƒåŸç†å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n![](https://github.com/hinthornw/trustcall/raw/main/_static/cover.png)","block_group":"69df6a24dd8a4deeac94f13a742e6d8f"},{"cell_type":"code","metadata":{"source_hash":"1f33d29a","execution_start":1729500842974,"execution_millis":4795,"is_output_hidden":true,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","deepnote_app_is_output_hidden":true,"cell_id":"275fc280deed4c95974c1a606bb0c372","deepnote_cell_type":"code"},"source":"!pip install trustcall","block_group":"5763a02bebfc4f3495f9695f63cca574","execution_count":8,"outputs":[{"name":"stdout","text":"Collecting trustcall\n  Downloading trustcall-0.0.22-py3-none-any.whl.metadata (29 kB)\nCollecting dydantic<0.0.8,>=0.0.7 (from trustcall)\n  Downloading dydantic-0.0.7-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /root/venv/lib/python3.11/site-packages (from trustcall) (1.33)\nRequirement already satisfied: langgraph>=0.2.25 in /root/venv/lib/python3.11/site-packages (from trustcall) (0.2.39)\nRequirement already satisfied: pydantic<3,>=2 in /root/venv/lib/python3.11/site-packages (from dydantic<0.0.8,>=0.0.7->trustcall) (2.9.2)\nRequirement already satisfied: jsonpointer>=1.9 in /shared-libs/python3.11/py-core/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->trustcall) (3.0.0)\nRequirement already satisfied: langchain-core<0.4,>=0.2.39 in /root/venv/lib/python3.11/site-packages (from langgraph>=0.2.25->trustcall) (0.3.12)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /root/venv/lib/python3.11/site-packages (from langgraph>=0.2.25->trustcall) (2.0.1)\nRequirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /root/venv/lib/python3.11/site-packages (from langgraph>=0.2.25->trustcall) (0.1.33)\nRequirement already satisfied: PyYAML>=5.3 in /shared-libs/python3.11/py-core/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (6.0.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /root/venv/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (0.1.136)\nRequirement already satisfied: packaging<25,>=23.2 in /shared-libs/python3.11/py-core/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (23.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /shared-libs/python3.11/py/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (8.2.3)\nRequirement already satisfied: typing-extensions>=4.7 in /root/venv/lib/python3.11/site-packages (from langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (4.12.2)\nRequirement already satisfied: msgpack<2.0.0,>=1.1.0 in /root/venv/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph>=0.2.25->trustcall) (1.1.0)\nRequirement already satisfied: httpx>=0.25.2 in /root/venv/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (0.27.2)\nRequirement already satisfied: httpx-sse>=0.4.0 in /root/venv/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (0.4.0)\nRequirement already satisfied: orjson>=3.10.1 in /root/venv/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (3.10.9)\nRequirement already satisfied: annotated-types>=0.6.0 in /shared-libs/python3.11/py/lib/python3.11/site-packages (from pydantic<3,>=2->dydantic<0.0.8,>=0.0.7->trustcall) (0.6.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /root/venv/lib/python3.11/site-packages (from pydantic<3,>=2->dydantic<0.0.8,>=0.0.7->trustcall) (2.23.4)\nRequirement already satisfied: anyio in /shared-libs/python3.11/py-core/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (4.0.0)\nRequirement already satisfied: certifi in /shared-libs/python3.11/py/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /root/venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (1.0.6)\nRequirement already satisfied: idna in /shared-libs/python3.11/py-core/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (3.4)\nRequirement already satisfied: sniffio in /shared-libs/python3.11/py-core/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /root/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph>=0.2.25->trustcall) (0.14.0)\nRequirement already satisfied: requests<3,>=2 in /root/venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (1.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /shared-libs/python3.11/py/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (3.3.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /shared-libs/python3.11/py/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph>=0.2.25->trustcall) (1.26.18)\nDownloading trustcall-0.0.22-py3-none-any.whl (22 kB)\nDownloading dydantic-0.0.7-py3-none-any.whl (8.6 kB)\nInstalling collected packages: dydantic, trustcall\nSuccessfully installed dydantic-0.0.7 trustcall-0.0.22\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/bb82233d-e03d-4b08-a5c2-ec9109b43b9d","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"a39eef4030494b198b2f983ea30372cb","deepnote_cell_type":"markdown"},"source":"## å¤„ç†å¤æ‚æ•°æ®ç»“æ„\n\né¦–å…ˆæˆ‘ä»¬ç»™å®šä¸€ä¸ªè¾ƒä¸ºå¤æ‚çš„ã€åµŒå¥—çš„æ•°æ®ç»“æ„ï¼Œå¹¶é€šè¿‡ä¼ ç»Ÿçš„æ–¹å¼æ¥å°è¯•å®ç°ç»“æ„åŒ–è¾“å‡ºã€‚","block_group":"628be8cf02e14844be5ac8c3aeac1110"},{"cell_type":"code","metadata":{"source_hash":"76aa65fc","execution_start":1729499552418,"execution_millis":131,"execution_context_id":"0e14cfdf-b081-4321-b4d2-09fd3fe61f2a","cell_id":"fae7ad220fde4d2ebf75798513efccbf","deepnote_cell_type":"code"},"source":"from typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass OutputFormat(BaseModel):\n    preference: str\n    sentence_preference_revealed: str\n\n\nclass TelegramPreferences(BaseModel):\n    preferred_encoding: Optional[List[OutputFormat]] = None\n    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n\n\nclass MorseCode(BaseModel):\n    preferred_key_type: Optional[List[OutputFormat]] = None\n    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n\n\nclass Semaphore(BaseModel):\n    preferred_flag_color: Optional[List[OutputFormat]] = None\n    semaphore_skill_level: Optional[List[OutputFormat]] = None\n\n\nclass TrustFallPreferences(BaseModel):\n    preferred_fall_height: Optional[List[OutputFormat]] = None\n    trust_level: Optional[List[OutputFormat]] = None\n    preferred_catching_technique: Optional[List[OutputFormat]] = None\n\n\nclass CommunicationPreferences(BaseModel):\n    telegram: TelegramPreferences\n    morse_code: MorseCode\n    semaphore: Semaphore\n\n\nclass UserPreferences(BaseModel):\n    communication_preferences: CommunicationPreferences\n    trust_fall_preferences: TrustFallPreferences\n\n\nclass TelegramAndTrustFallPreferences(BaseModel):\n    pertinent_user_preferences: UserPreferences","block_group":"c562fd2aa8064dd7a297cd4e594c3c14","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"f49c0e32","execution_start":1729499666374,"execution_millis":4725,"execution_context_id":"0e14cfdf-b081-4321-b4d2-09fd3fe61f2a","cell_id":"5f9393dd1e2d4ab4ab3bf9afb9ba531d","deepnote_cell_type":"code"},"source":"from langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o\")\nbound = llm.with_structured_output(TelegramAndTrustFallPreferences)\n\nconversation = \"\"\"Operator: How may I assist with your telegram, sir?\nCustomer: I need to send a message about our trust fall exercise.\nOperator: Certainly. Morse code or standard encoding?\nCustomer: Morse, please. I love using a straight key.\nOperator: Excellent. What's your message?\nCustomer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\nOperator: Done. Shall I use our \"Daredevil\" paper for this daring message?\nCustomer: Perfect! Send it by your fastest carrier pigeon.\nOperator: It'll be there within the hour, sir.\"\"\"\n\nbound.invoke(f\"\"\"Extract the preferences from the following conversation:\n<convo>\n{conversation}\n</convo>\"\"\")","block_group":"4b3f43e4216a42b9b051149a90b193a4","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"TelegramAndTrustFallPreferences(pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=None, favorite_telegram_operators=None, preferred_telegram_paper=[OutputFormat(preference='Daredevil', sentence_preference_revealed='Shall I use our \"Daredevil\" paper for this daring message?')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='straight key', sentence_preference_revealed='I love using a straight key.')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='higher', sentence_preference_revealed=\"Tell him I'm ready for a higher fall.\")], trust_level=None, preferred_catching_technique=[OutputFormat(preference='diamond formation', sentence_preference_revealed='I prefer the diamond formation for catching.')])))"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/a358bcda-a933-494d-bb95-6d0da4a245ce","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://smith.langchain.com/public/62752b98-91a4-48f3-a86f-043f284d324a/r","type":"link","ranges":[],"toCodePoint":92,"fromCodePoint":19}],"cell_id":"c28d741904714758ab4240fff75f6562","deepnote_cell_type":"text-cell-p"},"source":"ğŸ‘† LangSmith Trace: https://smith.langchain.com/public/62752b98-91a4-48f3-a86f-043f284d324a/r","block_group":"b658283ae5b2401791740c18ca0ca981"},{"cell_type":"code","metadata":{"source_hash":"4f1e7ab8","execution_start":1729500378214,"execution_millis":5176,"execution_context_id":"0e14cfdf-b081-4321-b4d2-09fd3fe61f2a","cell_id":"361f8f818bc7486ba638bd66e57f85a7","deepnote_cell_type":"code"},"source":"from langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\nbound = llm.with_structured_output(TelegramAndTrustFallPreferences)\n\nconversation = \"\"\"Operator: How may I assist with your telegram, sir?\nCustomer: I need to send a message about our trust fall exercise.\nOperator: Certainly. Morse code or standard encoding?\nCustomer: Morse, please. I love using a straight key.\nOperator: Excellent. What's your message?\nCustomer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\nOperator: Done. Shall I use our \"Daredevil\" paper for this daring message?\nCustomer: Perfect! Send it by your fastest carrier pigeon.\nOperator: It'll be there within the hour, sir.\"\"\"\n\nbound.invoke(f\"\"\"Extract the preferences from the following conversation:\n<convo>\n{conversation}\n</convo>\"\"\")","block_group":"2e91c9446cfe43409854b9e19e0b81c8","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"TelegramAndTrustFallPreferences(pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=[OutputFormat(preference='Morse', sentence_preference_revealed='I need to send a message about our trust fall exercise.')], favorite_telegram_operators=[OutputFormat(preference='Daredevil', sentence_preference_revealed='Shall I use our \"Daredevil\" paper for this daring message?')], preferred_telegram_paper=[OutputFormat(preference='Daredevil', sentence_preference_revealed='Shall I use our \"Daredevil\" paper for this daring message?')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='Straight Key', sentence_preference_revealed='I love using a straight key.')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='Higher Fall', sentence_preference_revealed=\"Tell him I'm ready for a higher fall.\")], trust_level=None, preferred_catching_technique=[OutputFormat(preference='Diamond Formation', sentence_preference_revealed='I prefer the diamond formation for catching.')])))"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/0b73e305-4efb-4619-901b-0282583dd494","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"81fc2204","execution_start":1729500388679,"execution_millis":21878,"execution_context_id":"0e14cfdf-b081-4321-b4d2-09fd3fe61f2a","cell_id":"49da56098ec84eacb7027851e134af2e","deepnote_cell_type":"code"},"source":"from trustcall import create_extractor\n\nbound = create_extractor(\n    llm,\n    tools=[TelegramAndTrustFallPreferences],\n    tool_choice=\"TelegramAndTrustFallPreferences\",\n)\n\nresult = bound.invoke(\n    f\"\"\"Extract the preferences from the following conversation:\n<convo>\n{conversation}\n</convo>\"\"\"\n)\nresult[\"responses\"][0]","block_group":"1d5c88cbf8724dfb957e7f8f5802a829","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"TelegramAndTrustFallPreferences(pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=[OutputFormat(preference='morse', sentence_preference_revealed='I prefer Morse code.')], favorite_telegram_operators=None, preferred_telegram_paper=[OutputFormat(preference='Daredevil', sentence_preference_revealed='I prefer the Daredevil paper.')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='straight key', sentence_preference_revealed='I love using a straight key.')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='higher', sentence_preference_revealed='I am ready for a higher fall.')], trust_level=None, preferred_catching_technique=[OutputFormat(preference='diamond formation', sentence_preference_revealed='I prefer the diamond formation for catching.')])))"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/678eb347-d28e-4084-861b-7d2008ef65a9","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://smith.langchain.com/public/a80f3a38-1e40-4b79-b04a-a9aa69947157/r","type":"link","ranges":[],"toCodePoint":92,"fromCodePoint":19}],"cell_id":"73a9c3890f2441e29e58caf690dce22c","deepnote_cell_type":"text-cell-p"},"source":"ğŸ‘† LangSmith Trace: https://smith.langchain.com/public/a80f3a38-1e40-4b79-b04a-a9aa69947157/r","block_group":"fff2e5ddf6e34611ac95d70a23c690e1"},{"cell_type":"markdown","metadata":{"cell_id":"cf874ce231c74d8bb7610a266cdfc6ab","deepnote_cell_type":"markdown"},"source":"## å¤„ç†æ•°æ®ç»“æ„æ›´æ–°\n\nè®¸å¤šä»»åŠ¡æœŸæœ›ä½¿ç”¨ LLM æ ¹æ®æ–°ä¿¡æ¯æ›´æ­£æˆ–ä¿®æ”¹ç°æœ‰å¯¹è±¡ã€‚\n\nä»¥å†…å­˜ç®¡ç†ä¸ºä¾‹ã€‚å‡è®¾æ‚¨å°†å†…å­˜ç»“æ„åŒ–ä¸º JSON å¯¹è±¡ã€‚å½“æä¾›æ–°ä¿¡æ¯æ—¶ï¼ŒLLM å¿…é¡»å°†æ­¤ä¿¡æ¯ä¸ç°æœ‰æ–‡æ¡£è¿›è¡Œåè°ƒã€‚è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨æ–‡æ¡£çš„ç®€å•å†ç”Ÿæ¥è¯•è¯•ã€‚æˆ‘ä»¬å°†å†…å­˜å»ºæ¨¡ä¸ºå•ä¸ªç”¨æˆ·èµ„æ–™ï¼š","block_group":"10136899164c423798fee868521ebdb9"},{"cell_type":"code","metadata":{"source_hash":"cd27d8a2","execution_start":1729500655998,"execution_millis":85,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"500f7b1b4b8d4200b89ccd17d9b32188","deepnote_cell_type":"code"},"source":"from typing import Dict, List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    postal_code: str\n\n\nclass Pet(BaseModel):\n    kind: str\n    name: Optional[str]\n    age: Optional[int]\n\n\nclass Hobby(BaseModel):\n    name: str\n    skill_level: str\n    frequency: str\n\n\nclass FavoriteMedia(BaseModel):\n    shows: List[str]\n    movies: List[str]\n    books: List[str]\n\n\nclass User(BaseModel):\n    preferred_name: str\n    favorite_media: FavoriteMedia\n    favorite_foods: List[str]\n    hobbies: List[Hobby]\n    age: int\n    occupation: str\n    address: Address\n    favorite_color: Optional[str] = None\n    pets: Optional[List[Pet]] = None\n    languages: Dict[str, str] = {}","block_group":"fe97128216cb45068827b246dfdd97e3","execution_count":1,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"c7f11d92","execution_start":1729500661420,"execution_millis":5,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"01bdadbdde054706ae61619a909d288a","deepnote_cell_type":"code"},"source":"initial_user = User(\n    preferred_name=\"Alex\",\n    favorite_media=FavoriteMedia(\n        shows=[\n            \"Friends\",\n            \"Game of Thrones\",\n            \"Breaking Bad\",\n            \"The Office\",\n            \"Stranger Things\",\n        ],\n        movies=[\"The Shawshank Redemption\", \"Inception\", \"The Dark Knight\"],\n        books=[\"1984\", \"To Kill a Mockingbird\", \"The Great Gatsby\"],\n    ),\n    favorite_foods=[\"sushi\", \"pizza\", \"tacos\", \"ice cream\", \"pasta\", \"curry\"],\n    hobbies=[\n        Hobby(name=\"reading\", skill_level=\"expert\", frequency=\"daily\"),\n        Hobby(name=\"hiking\", skill_level=\"intermediate\", frequency=\"weekly\"),\n        Hobby(name=\"photography\", skill_level=\"beginner\", frequency=\"monthly\"),\n        Hobby(name=\"biking\", skill_level=\"intermediate\", frequency=\"weekly\"),\n        Hobby(name=\"swimming\", skill_level=\"expert\", frequency=\"weekly\"),\n        Hobby(name=\"canoeing\", skill_level=\"beginner\", frequency=\"monthly\"),\n        Hobby(name=\"sailing\", skill_level=\"intermediate\", frequency=\"monthly\"),\n        Hobby(name=\"weaving\", skill_level=\"beginner\", frequency=\"weekly\"),\n        Hobby(name=\"painting\", skill_level=\"intermediate\", frequency=\"weekly\"),\n        Hobby(name=\"cooking\", skill_level=\"expert\", frequency=\"daily\"),\n    ],\n    age=28,\n    occupation=\"Software Engineer\",\n    address=Address(\n        street=\"123 Tech Lane\", city=\"San Francisco\", country=\"USA\", postal_code=\"94105\"\n    ),\n    favorite_color=\"blue\",\n    pets=[Pet(kind=\"cat\", name=\"Luna\", age=3)],\n    languages={\"English\": \"native\", \"Spanish\": \"intermediate\", \"Python\": \"expert\"},\n)","block_group":"0ec3273e03914bc18656014eb2b902a2","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"f2f66808","execution_start":1729501123021,"execution_millis":4499,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"9331b034282d49b4bc40756f0ea0d580","deepnote_cell_type":"code"},"source":"conversation = \"\"\"Friend: Hey Alex, how's the new job going? I heard you switched careers recently.\nAlex: It's going great! I'm loving my new role as a Data Scientist. The work is challenging but exciting. I've moved to a new apartment in New York to be closer to the office.\nFriend: That's a big change! Are you still finding time for your hobbies?\nAlex: Well, I've had to cut back on some. I'm not doing much sailing or canoeing these days. But I've gotten really into machine learning projects in my free time. I'd say I'm getting pretty good at it - probably an intermediate level now.\nFriend: Sounds like you're keeping busy! How's Luna doing?\nAlex: Oh, Luna's great. She just turned 4 last week. She's actually made friends with my new pet, Max the dog. He's a playful 2-year-old golden retriever.\nFriend: Two pets now! That's exciting. Hey, want to catch the new season of Stranger Things this weekend?\nAlex: Actually, I've kind of lost interest in that show. But I'm really into this new series called \"The Mandalorian\". We could watch that instead! Oh, and I recently watched \"Parasite\" - it's become one of my favorite movies.\nFriend: Sure, that sounds fun. Should I bring some food? I remember you love sushi.\nAlex: Sushi would be perfect! Or maybe some Thai food - I've been really into that lately. By the way, I've been practicing my French. I'd say I'm at a beginner level now.\nFriend: That's great! You're always learning something new. How's the cooking going?\nAlex: It's going well! I've been cooking almost every day now. I'd say I've become quite proficient at it.\"\"\"\n\n\n# Naive approach\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\nbound = llm.with_structured_output(User)\nnaive_result = bound.invoke(\n    f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation:\n<user_info>\n{initial_user.model_dump()}\n</user_info>\n<convo>\n{conversation}\n</convo>\"\"\"\n)\nprint(\"Naive approach result:\")\nnaive_output = naive_result.model_dump()\nprint(naive_output)","block_group":"f27e448e78cc4cf09abf2e75853dcb20","execution_count":14,"outputs":[{"name":"stdout","text":"Naive approach result:\n{'preferred_name': 'Alex', 'favorite_media': {'shows': ['Friends', 'Game of Thrones', 'Breaking Bad', 'The Office', 'The Mandalorian'], 'movies': ['The Shawshank Redemption', 'Inception', 'The Dark Knight', 'Parasite'], 'books': ['1984', 'To Kill a Mockingbird', 'The Great Gatsby']}, 'favorite_foods': ['sushi', 'pizza', 'tacos', 'ice cream', 'pasta', 'curry', 'Thai food'], 'hobbies': [{'name': 'reading', 'skill_level': 'expert', 'frequency': 'daily'}, {'name': 'hiking', 'skill_level': 'intermediate', 'frequency': 'weekly'}, {'name': 'photography', 'skill_level': 'beginner', 'frequency': 'monthly'}, {'name': 'biking', 'skill_level': 'intermediate', 'frequency': 'weekly'}, {'name': 'swimming', 'skill_level': 'expert', 'frequency': 'weekly'}, {'name': 'sailing', 'skill_level': 'intermediate', 'frequency': 'monthly'}, {'name': 'weaving', 'skill_level': 'beginner', 'frequency': 'weekly'}, {'name': 'painting', 'skill_level': 'intermediate', 'frequency': 'weekly'}, {'name': 'cooking', 'skill_level': 'expert', 'frequency': 'daily'}, {'name': 'machine learning projects', 'skill_level': 'intermediate', 'frequency': 'weekly'}], 'age': 28, 'occupation': 'Data Scientist', 'address': {'street': '123 Tech Lane', 'city': 'New York', 'country': 'USA', 'postal_code': '94105'}, 'favorite_color': 'blue', 'pets': [{'kind': 'cat', 'name': 'Luna', 'age': 4}, {'kind': 'dog', 'name': 'Max', 'age': 2}], 'languages': {'English': 'native', 'Spanish': 'intermediate', 'Python': 'expert', 'French': 'beginner'}}\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/124e49dd-7742-4790-843c-316fd1f1fb5f","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"3cf459ea","execution_start":1729501142698,"execution_millis":6426,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"aa07ddf07e594f70976b3b040a88e7d9","deepnote_cell_type":"code"},"source":"# Trustcall approach\nfrom trustcall import create_extractor\n\nbound = create_extractor(llm, tools=[User])\n\ntrustcall_result = bound.invoke(\n    {\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation:\n<convo>\n{conversation}\n</convo>\"\"\",\n            }\n        ],\n        \"existing\": {\"User\": initial_user.model_dump()},\n    }\n)\nprint(\"\\nTrustcall approach result:\")\ntrustcall_output = trustcall_result[\"responses\"][0].model_dump()\nprint(trustcall_output)","block_group":"27f99ccc860244bfb31c21f4ccd0f485","execution_count":15,"outputs":[{"name":"stderr","text":"Could not apply patch: can't replace a non-existent object 'French'\n\nTrustcall approach result:\n","output_type":"stream"},{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m      6\u001b[0m trustcall_result \u001b[38;5;241m=\u001b[39m bound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m      7\u001b[0m     {\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTrustcall approach result:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m trustcall_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrustcall_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(trustcall_output)\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/3d0f1536-2493-4c92-976f-cd9f496fc76f","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"5f4f8d5b1c114a6e902c36cd93b69901","deepnote_cell_type":"markdown"},"source":"## å¤„ç†åŒæ—¶æ’å…¥å’Œæ›´æ–°\n\nä¸Šè¿°ä¸¤ä¸ªé—®é¢˜ï¼ˆåœ¨ç”Ÿæˆå¤æ‚æ¨¡å¼æ—¶ç±»å‹å®‰å…¨çš„ç”Ÿæˆå›°éš¾ä»¥åŠç”Ÿæˆç°æœ‰æ¨¡å¼çš„æ­£ç¡®ç¼–è¾‘å›°éš¾ï¼‰åœ¨æ‚¨å¿…é¡»æç¤º LLM åŒæ—¶å¤„ç†æ›´æ–°å’Œæ’å…¥æ—¶æ›´åŠ å¤æ‚ï¼Œè¿™åœ¨ä»å¯¹è¯ä¸­æå–å¤šä¸ªå†…å­˜â€œäº‹ä»¶â€æ—¶é€šå¸¸æ˜¯æƒ…å†µã€‚","block_group":"991637bfc2eb4446bb37cfbf6e9bc1e2"},{"cell_type":"code","metadata":{"source_hash":"a7138af9","execution_start":1729501330734,"execution_millis":0,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"f304b799ff5c493abf1fb7988f2fc09e","deepnote_cell_type":"code"},"source":"import uuid\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass Person(BaseModel):\n    \"\"\"Someone the user knows or interacts with.\"\"\"\n\n    name: str\n    relationship: str = Field(description=\"How they relate to the user.\")\n\n    notes: List[str] = Field(\n        description=\"Memories and other observations about the person\"\n    )\n\n\n# Initial data\ninitial_people = [\n    Person(\n        name=\"Emma Thompson\",\n        relationship=\"College friend\",\n        notes=[\"Loves hiking\", \"Works in marketing\", \"Has a dog named Max\"],\n    ),\n    Person(\n        name=\"Michael Chen\",\n        relationship=\"Coworker\",\n        notes=[\"Great at problem-solving\", \"Vegetarian\", \"Plays guitar\"],\n    ),\n    Person(\n        name=\"Sarah Johnson\",\n        relationship=\"Neighbor\",\n        notes=[\"Has two kids\", \"Loves gardening\", \"Makes amazing cookies\"],\n    ),\n]\n\n# Convert to the format expected by the extractor\nexisting_data = [\n    (str(i), \"Person\", person.model_dump()) for i, person in enumerate(initial_people)\n]","block_group":"b25f844221c24d60ad341f4ead05784f","execution_count":16,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"36958a7c","execution_start":1729501532722,"execution_millis":5769,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"28ada08db6f34236ac7a3580b629896c","deepnote_cell_type":"code"},"source":"conversation = \"\"\"\nMe: I ran into Emma Thompson at the park yesterday. She was walking her new puppy, a golden retriever named Sunny. She mentioned she got promoted to Senior Marketing Manager last month.\nFriend: That's great news for Emma! How's she enjoying the new role?\nMe: She seems to be thriving. Oh, and did you know she's taken up rock climbing? She invited me to join her at the climbing gym sometime.\nFriend: Wow, rock climbing? That's quite a change from hiking. Speaking of friends, have you heard from Michael Chen recently?\nMe: Actually, yes. We had a video call last week. He's switched jobs and is now working as a Data Scientist at a startup. He's also mentioned he's thinking of going vegan.\nFriend: That's a big change for Michael! Both career and diet-wise. How about your neighbor, Sarah? Is she still teaching?\nMe: Sarah's doing well. Her kids are growing up fast - her oldest just started middle school. She's still teaching, but now she's focusing on special education. She's really passionate about it.\nFriend: That's wonderful. Oh, before I forget, I wanted to introduce you to my cousin who just moved to town. Her name is Olivia Davis, she's a 27-year-old graphic designer. She's looking to meet new people and expand her social circle. I thought you two might get along well.\nMe: That sounds great! I'd love to meet her. Maybe we could all get together for coffee next week?\nFriend: Perfect! I'll set it up. Olivia loves art and is always sketching in her free time. She also volunteers at the local animal shelter on weekends.\n\"\"\"\n\nfrom langchain_openai import ChatOpenAI\n\n# Now, let's use the extractor to update existing entries and create new ones\nfrom trustcall import create_extractor\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n\nextractor = create_extractor(\n    llm,\n    tools=[Person],\n    tool_choice=\"any\",\n    enable_inserts=True,\n)\n\nresult = extractor.invoke(\n    {\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": f\"Update existing person records and create new ones based on the following conversation:\\n\\n{conversation}\",\n            }\n        ],\n        \"existing\": existing_data,\n    }\n)\n\n# Print the results\nprint(\"Updated and new person records:\")\nfor r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n    print(f\"ID: {rmeta.get('json_doc_id', 'New')}\")\n    print(r.model_dump_json(indent=2))\n    print()","block_group":"573180b49d4d4c26a1142269ceb9abc9","execution_count":19,"outputs":[{"name":"stdout","text":"Updated and new person records:\nID: 0\n{\n  \"name\": \"Emma Thompson\",\n  \"relationship\": \"College friend\",\n  \"notes\": [\n    \"Loves hiking\",\n    \"Works in marketing\",\n    \"Has a dog named Sunny\",\n    \"Got promoted to Senior Marketing Manager\",\n    \"Took up rock climbing\"\n  ]\n}\n\nID: 1\n{\n  \"name\": \"Michael Chen\",\n  \"relationship\": \"Coworker\",\n  \"notes\": [\n    \"Great at problem-solving\",\n    \"Thinking of going vegan\",\n    \"Switched jobs to Data Scientist at a startup\"\n  ]\n}\n\nID: 2\n{\n  \"name\": \"Sarah Johnson\",\n  \"relationship\": \"Neighbor\",\n  \"notes\": [\n    \"Her oldest just started middle school\",\n    \"Loves gardening\",\n    \"Makes amazing cookies\",\n    \"Focusing on special education\"\n  ]\n}\n\nID: New\n{\n  \"name\": \"Olivia Davis\",\n  \"relationship\": \"Cousin of a friend\",\n  \"notes\": [\n    \"27-year-old graphic designer\",\n    \"Loves art and sketching\",\n    \"Volunteers at the local animal shelter on weekends\"\n  ]\n}\n\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/386a5f92-7117-4de8-a7e5-9a5335c49522","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://smith.langchain.com/public/50b8479f-4753-4d4a-b8da-f21e0f658914/r","type":"link","ranges":[],"toCodePoint":92,"fromCodePoint":19}],"cell_id":"27deb3d0e31445fd8b1fe62785a5924b","deepnote_cell_type":"text-cell-p"},"source":"ğŸ‘† LangSmith Trace: https://smith.langchain.com/public/50b8479f-4753-4d4a-b8da-f21e0f658914/r","block_group":"71511936930345198ec29285ea449351"},{"cell_type":"markdown","metadata":{"cell_id":"4d34ce359da54301b3f28c8a277263d5","deepnote_cell_type":"markdown"},"source":"## åœ¨ LangGraph ä¸­çš„ä½¿ç”¨","block_group":"36a845a027074cab81e4cd0cf703dc9f"},{"cell_type":"code","metadata":{"source_hash":"9b21ac60","execution_start":1729504452322,"execution_millis":1,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"5eb7a6130c9548b89a5e3a752186d0fc","deepnote_cell_type":"code"},"source":"import operator\nfrom datetime import datetime\nfrom typing import List\n\nimport pytz\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import START, StateGraph\nfrom langgraph.prebuilt import ToolNode, tools_condition\nfrom pydantic.v1 import BaseModel, Field, validator\nfrom trustcall import create_extractor\nfrom typing_extensions import Annotated, TypedDict\n\n\nclass Preferences(BaseModel):\n    foods: List[str] = Field(description=\"Favorite foods\")\n\n    @validator(\"foods\")\n    def at_least_three_foods(cls, v):\n        if len(v) < 3:\n            raise ValueError(\"Must have at least three favorite foods\")\n        return v\n\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n\n\ndef save_user_information(preferences: Preferences):\n    \"\"\"Save user information to a database.\"\"\"\n    return \"User information saved\"\n\n\ndef lookup_time(tz: str) -> str:\n    \"\"\"Lookup the current time in a given timezone.\"\"\"\n    try:\n        # Convert the timezone string to a timezone object\n        timezone = pytz.timezone(tz)\n        # Get the current time in the given timezone\n        tm = datetime.now(timezone)\n        return f\"The current time in {tz} is {tm.strftime('%H:%M:%S')}\"\n    except pytz.UnknownTimeZoneError:\n        return f\"Unknown timezone: {tz}\"\n\n\nagent = create_extractor(llm, tools=[save_user_information, lookup_time])\n\n\nclass State(TypedDict):\n    messages: Annotated[list, operator.add]\n\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"agent\", agent)\nbuilder.add_node(\"tools\", ToolNode([save_user_information, lookup_time]))\nbuilder.add_edge(\"tools\", \"agent\")\nbuilder.add_edge(START, \"agent\")\nbuilder.add_conditional_edges(\"agent\", tools_condition)\n\ngraph = builder.compile(checkpointer=MemorySaver())\n","block_group":"9a93cd2891204a9bb574b91677b7b804","execution_count":51,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"1b0b5928","execution_start":1729502951548,"execution_millis":1964,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"33ef4061116149fc98950bc9faf36578","deepnote_cell_type":"code"},"source":"config = {\"configurable\": {\"thread_id\": \"1234\"}}\nres = graph.invoke({\"messages\": [(\"user\", \"Hi there!\")]}, config)\nres[\"messages\"][-1].pretty_print()","block_group":"73460f273f8746b797bc0d801ea7eba2","execution_count":40,"outputs":[{"name":"stdout","text":"==================================\u001b[1m Ai Message \u001b[0m==================================\n\nHello! How can I assist you today?\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/0dd9026c-5179-466b-8302-779c0f7e14d0","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"d2e2ed84","execution_start":1729502957646,"execution_millis":1892,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"17e0b9755bd34e359b699b3477700ca1","deepnote_cell_type":"code"},"source":"res = graph.invoke(\n    {\"messages\": [(\"user\", \"Curious; what's the time in denver right now?\")]}, config\n)\nres[\"messages\"][-1].pretty_print()","block_group":"56b77d849c7f4390970254d1d85092e5","execution_count":41,"outputs":[{"name":"stdout","text":"==================================\u001b[1m Ai Message \u001b[0m==================================\n\nThe current time in Denver is 3:29 AM.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/73312a81-9fd9-47a3-92ad-95d5c955e361","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"b1575e81","execution_start":1729504460912,"execution_millis":6794,"execution_context_id":"3807a764-af73-4055-975f-23382eeaf354","cell_id":"1dabfb572a1547d2a306040aec5b9dd7","deepnote_cell_type":"code"},"source":"res = graph.invoke(\n    {\n        \"messages\": [\n            (\"user\", \"Did you know my favorite foods are spinach and potatoes?\")\n        ]\n    },\n    config,\n)\nres[\"messages\"][-1].pretty_print()","block_group":"46f0a216bef84962bed9b0ac2470ed18","execution_count":52,"outputs":[{"output_type":"error","ename":"ValidationError","evalue":"1 validation error for save_user_information\npreferences -> foods\n  Must have at least three favorite foods (type=value_error)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDid you know my favorite foods are spinach and potatoes?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1586\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1586\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1315\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1310\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1311\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1312\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1313\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1314\u001b[0m     ):\n\u001b[0;32m-> 1315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1322\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:412\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4713\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4700\u001b[0m \n\u001b[1;32m   4701\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4710\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4715\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4716\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4717\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4718\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4720\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4723\u001b[0m     )\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1926\u001b[0m         Output,\n\u001b[0;32m-> 1927\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1935\u001b[0m     )\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:4567\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4565\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4567\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4570\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/trustcall/_base.py:376\u001b[0m, in \u001b[0;36mcreate_extractor.<locals>.filter_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tc \u001b[38;5;129;01min\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[1;32m    372\u001b[0m     sch \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mschemas_by_name[tc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    373\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    374\u001b[0m         sch\u001b[38;5;241m.\u001b[39mmodel_validate(tc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_validate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 376\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     )\n\u001b[1;32m    378\u001b[0m     meta \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: tc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json_doc_id \u001b[38;5;241m:=\u001b[39m updated_docs\u001b[38;5;241m.\u001b[39mget(tc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    524\u001b[0m         exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected dict not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/venv/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for save_user_information\npreferences -> foods\n  Must have at least three favorite foods (type=value_error)"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/48cec654-28eb-491d-bf58-ab604d807c7a","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://smith.langchain.com/public/41407f66-7ed4-4870-8fa6-7beca3c5e90f/r","type":"link","ranges":[],"toCodePoint":92,"fromCodePoint":19}],"cell_id":"70fb02ca921845d8bf1d44e30fc3221d","deepnote_cell_type":"text-cell-p"},"source":"ğŸ‘† LangSmith Trace: https://smith.langchain.com/public/41407f66-7ed4-4870-8fa6-7beca3c5e90f/r","block_group":"c0aaa51728b14641af8d1b7e9d90f83f"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://smith.langchain.com/public/b83d6db1-ffb9-4817-a166-bbc5004bbc25/r/5a05f73b-1d7e-47d4-9e40-0e8aaa3faa28","type":"link","ranges":[],"toCodePoint":139,"fromCodePoint":29}],"cell_id":"eaefb4ae48da44d287c651bab6266ea7","deepnote_cell_type":"text-cell-p"},"source":"ğŸŒ° Fireworks Firefunction v2: https://smith.langchain.com/public/b83d6db1-ffb9-4817-a166-bbc5004bbc25/r/5a05f73b-1d7e-47d4-9e40-0e8aaa3faa28 ","block_group":"0e6c8c25fb094dafa269ef10db8091ef"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e6124301-0a3c-4c43-a70b-884a597351fa' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"937f5aed2fc048f7967a3a3e7ce1a3fd","deepnote_execution_queue":[]}}